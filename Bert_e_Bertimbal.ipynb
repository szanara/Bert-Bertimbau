{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-zcgf6mN7Km8"
      },
      "outputs": [],
      "source": [
        "#!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "0zUjRiIAlvjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "rQhj5TfU7PfI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ybvz_njv7RGC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "NqIQaKefIBpe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import AdamW\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "S3DUBiQc79mi"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhbJSjF_7Sj0",
        "outputId": "9e5920c4-f101-44a7-85ea-51403f559a41"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBL5jVMD7T-P",
        "outputId": "cf65627e-3f61-4c58-a411-da40254412fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1CNLowRdVtLOrHbCZbdjg3IVys53iPk7m/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "O dataset usado é o sobre notícias, para classificá-las conforme a categoria desta."
      ],
      "metadata": {
        "id": "Ocv7MmL0mSvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "input_file = 'articles.csv'\n",
        "output_file = 'corrected_articles.csv'\n",
        "\n",
        "# Lista para armazenar as linhas válidas\n",
        "data = []\n",
        "\n",
        "# Ler o arquivo CSV manualmente\n",
        "with open(input_file, 'r', encoding='utf-8') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    header = next(reader)  # Ler o cabeçalho\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "# Criar o DataFrame a partir dos dados\n",
        "art_df = pd.DataFrame(data, columns=header)\n"
      ],
      "metadata": {
        "id": "AcmNBsoj7Vq4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "art_df.columns\n",
        "art_df = art_df.drop(columns = ['title','date','subcategory', 'link'])"
      ],
      "metadata": {
        "id": "6Mms4gw_7kcT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Conforme a documentação do site do Hugging Face, é necessário realizar a tokenização dos textos que serão utilizados no treinamento para o fine-tuning desses modelos. Dessa forma, e ate por uma questão de memoria, optei por manter apenas as colunas que contêm o corpo da notícia e a categoria à qual ela pertence.\n"
      ],
      "metadata": {
        "id": "bO93aiu5npnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Codificar as categorias\n",
        "label_encoder = LabelEncoder()\n",
        "art_df['category'] = label_encoder.fit_transform(art_df['category'])\n",
        "art_df = art_df.rename(columns={'category': 'label'})\n"
      ],
      "metadata": {
        "id": "xAq4qqGX7mjz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As classes estão no formato de texto, o que não é ideal para o treinamento do modelo. Portanto, a função `label_encoder` converte as classes nominais em formatos numéricos"
      ],
      "metadata": {
        "id": "6dXubQXvoha-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicação da operação usando pandas e tqdm para acompanhar o progresso\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()  # Ativar tqdm com pandas\n",
        "\n",
        "# Função para truncar o texto após o último ponto\n",
        "def truncate_text(s):\n",
        "    if isinstance(s, str):\n",
        "        return s[:s.rfind('.') + 1]\n",
        "    return ''\n",
        "\n",
        "# Aplicar a função para truncar o texto\n",
        "art_df['text'] = art_df['text'].progress_apply(truncate_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm41NHf97ogw",
        "outputId": "af962dc2-1312-458c-e22a-1d6e2d1fba1a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 167053/167053 [00:00<00:00, 425392.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante o processo de tokenização, estava enfrentando problemas. A tokenização retornava erros e não funcionava, até que ao buscar tutoriais, foi possível perceber que o problema era que o texto não estava sendo encerrado com '.'. Ou seja, mesmo que o corpo da notícia tivesse terminado, havia ruídos como propaganda após o corpo da mensagem, o que necessitava de uma limpeza para manter o padrão. O Transformer interpreta ',' como uma forma de parada, então a falta de finalização da mensagem acabava causando erro. `trucate_text` resolve esse problema."
      ],
      "metadata": {
        "id": "KNMOfcLUpIim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divida o DataFrame em treinamento (80%) e uma parte temporária (20%)\n",
        "df_train, df_temp = train_test_split(art_df, test_size=0.9999, random_state=10)\n",
        "\n",
        "# Divida a parte temporária em validação (50%) e teste (50%)\n",
        "df_val, df_test = train_test_split(df_train, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "JWLNIFaL7qcY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta etapa de divisão dos dados é bastante delicada. O conjunto de dados é muito grande e estava estourando a memória, então precisei utilizar uma configuração que permitisse executar os experimentos. Como acredito que o objetivo da atividade seja testar nossas habilidades com os modelos, aprender a pré-processá-los, entre outros aspectos, não vejo problema quanto ao tamanho dos dados que consigo usar nos experimentos."
      ],
      "metadata": {
        "id": "w3dzPUeWqImY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9E1UqeJ7sLU",
        "outputId": "28b9de07-2cbe-44c4-bed9-a01fe6014145"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16, 2), (8, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "def remove_missing_classes(df_train, df_test):\n",
        "  \"\"\"\n",
        "  Removes rows in df_train where the label is present in df_train but not in df_test.\n",
        "\n",
        "  Args:\n",
        "      df_train (pandas.DataFrame): The training DataFrame.\n",
        "      df_test (pandas.DataFrame): The testing DataFrame.\n",
        "\n",
        "  Returns:\n",
        "      pandas.DataFrame: The filtered df_train with missing classes removed.\n",
        "  \"\"\"\n",
        "\n",
        "  classes_train = set(df_train['label'].unique())\n",
        "  classes_test = set(df_test['label'].unique())\n",
        "\n",
        "  missing_classes = classes_train.difference(classes_test)\n",
        "\n",
        "  return df_train[~df_train['label'].isin(missing_classes)]\n",
        "\n",
        "# Example usage:\n",
        "df_train = remove_missing_classes(df_train, df_test)\n",
        "print(set(df_train['label']))\n",
        "print(set(df_test['label'].unique()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMVkvM367uda",
        "outputId": "fe6a4145-0fea-4541-8dfd-9ba2fb6eda18"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{35, 9, 12, 46, 26}\n",
            "{35, 9, 12, 46, 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Devido ao tamanho do dataset, algumas classes estão presentes no conjunto de treino mas ausentes no conjunto de teste, o que gera problemas. Por isso, a função `removing_missing_classes` tem o objetivo de garantir que ambos os conjuntos tenham as mesmas classes."
      ],
      "metadata": {
        "id": "KxcgrauoquBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função de Treino\n",
        "\n",
        "A função `train_evaluate_model` foi criada para ser utilizada com os dois modelos solicitados, permitindo uma comparação mais justa dos resultados. Para isso, ela recebe os modelos, tokenizers, além dos conjuntos de treino (já tokenizados) e teste"
      ],
      "metadata": {
        "id": "M7pTDc7NrKcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_model(tokenizer, model, tokenized_train, tokenized_test, y_train, y_test):\n",
        "\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "    train_dataset = TensorDataset(\n",
        "        tokenized_train[\"input_ids\"].clone().detach(),\n",
        "        tokenized_train[\"attention_mask\"].clone().detach(),\n",
        "        torch.tensor(y_train)\n",
        "    )\n",
        "    test_dataset = TensorDataset(\n",
        "        tokenized_test[\"input_ids\"].clone().detach(),\n",
        "        tokenized_test[\"attention_mask\"].clone().detach(),\n",
        "        torch.tensor(y_test)\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device='cpu'\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1):  # Loop over epochs\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Debugging: Print shapes and values\n",
        "            #print(\"Batch input_ids shape train :\", input_ids.shape)\n",
        "            #print(\"Batch attention_mask shape train :\", attention_mask.shape)\n",
        "            #print(\"Batch labels shape train:\", labels.shape)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    acc = []\n",
        "    prec =[]\n",
        "    num_classes = len(set(y_test))\n",
        "    overall_cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Debugging: Print shapes and values\n",
        "            #print(\"Batch input_ids shape:\", input_ids.shape)\n",
        "            #print(\"Batch attention_mask shape:\", attention_mask.shape)\n",
        "            #print(\"Batch labels shape:\", labels.shape)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "            eval_loss += outputs.loss.item()\n",
        "\n",
        "\n",
        "\n",
        "            accuracy = accuracy_score(labels, predictions)\n",
        "            acc.append(accuracy)\n",
        "\n",
        "            precision = precision_score(labels, predictions, average=\"weighted\")\n",
        "            prec.append(precision)\n",
        "\n",
        "            print(f\"Accuracy: {accuracy:.3f}\")\n",
        "            print(f\"Precision: {precision:.3f}\")\n",
        "\n",
        "\n",
        "        average_accuracy = np.mean(acc)\n",
        "        average_precision = np.mean(prec)\n",
        "\n",
        "        print(f\"Average Accuracy: {average_accuracy:.3f}\")\n",
        "        print(f\"Average Precision: {average_precision:.3f}\")\n",
        "        print(f\"Evaluation Loss: {eval_loss / len(test_dataloader)}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TGTszbtD7zhO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregamento dos Bertimbal\n",
        "\n",
        "Vamos fazer tudo primeiro pra o Bertimbal e depois para o Bert"
      ],
      "metadata": {
        "id": "R-faqAEVrueI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Carregamento dos modelos BERT e Bertimbal\n",
        "\n",
        "bertimbal_tokenizer = AutoTokenizer.from_pretrained(\"tiagoblima/newsdata-bertimbal\")\n",
        "bertimbal_model = AutoModelForSequenceClassification.from_pretrained(\"tiagoblima/newsdata-bertimbal\")\n"
      ],
      "metadata": {
        "id": "4XLb2Syi9Rxs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Peparação final dos dados\n",
        "\n",
        "Os datasets precisam ser objetos do tipo dataset. Portanto, é necessário converter tanto o conjunto de treino quanto o de teste para esse formato. Além disso, como a seleção dos dados anteriormente foi feita de maneira aleatória, as classes resultantes no meu dataset podem não estar ordenadas. Por isso, a função convert_class_labels associa cada classe a uma ordem numérica (0, 1, 2, etc.), evitando problemas durante o treinamento."
      ],
      "metadata": {
        "id": "baNAN7ucrybi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = Dataset.from_pandas(df_train)\n",
        "dataset_test = Dataset.from_pandas(df_test)"
      ],
      "metadata": {
        "id": "aCXq7NV59YI-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = dataset_train['label']\n",
        "y_test = dataset_test['label']"
      ],
      "metadata": {
        "id": "kf84KqML9rR0"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_class_labels(labels):\n",
        "  \"\"\"\n",
        "  Converts a list of class labels (integers) to numerical representations (starting from 0).\n",
        "\n",
        "  Args:\n",
        "      labels (list): A list of integer class labels.\n",
        "\n",
        "  Returns:\n",
        "      torch.Tensor: A tensor containing the numerical representations of the class labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a dictionary to map unique class labels to numerical representations\n",
        "  class_to_index = {label: i for i, label in enumerate(sorted(set(labels)))}\n",
        "\n",
        "  # Convert each label in the original list to its numerical representation\n",
        "  numerical_labels = [class_to_index[label] for label in labels]\n",
        "\n",
        "  # Convert the list to a PyTorch tensor\n",
        "  return numerical_labels"
      ],
      "metadata": {
        "id": "AwfBONJiCIhc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = convert_class_labels(y_train)\n",
        "y_test =  convert_class_labels(y_test)"
      ],
      "metadata": {
        "id": "jhuY-n2xCLxZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(y_train), set(y_test), len(dataset_test[\"text\"]), len(y_test), len(dataset_train[\"text\"]), len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KoPDtseLHoj",
        "outputId": "3e60136a-c851-43e5-aed3-40437cabd589"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, 8, 8, 12, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenização, Treino e Avaliação dos modelos."
      ],
      "metadata": {
        "id": "eBYvnSKYspLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_bertimbau_train = bertimbal_tokenizer(dataset_train[\"text\"], padding=\"max_length\", truncation=True, max_length=300, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "olVThxw59tjZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_bertimbau_test = bertimbal_tokenizer(dataset_test[\"text\"], padding=\"max_length\", truncation=True, max_length=300, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "oYStrlpsAlCS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(bertimbal_tokenizer, bertimbal_model, tokenized_bertimbau_train, tokenized_bertimbau_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57iQyrr3AoBx",
        "outputId": "dceeaf88-77a4-4fa8-c562-0563595b8b3a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.000\n",
            "Precision: 1.000\n",
            "Accuracy: 1.000\n",
            "Precision: 1.000\n",
            "Average Accuracy: 1.000\n",
            "Average Precision: 1.000\n",
            "Evaluation Loss: 0.0019725957536138594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo é avaliado em batches, por isso imprimo as acurácias e precisões de cada um. Como ambos são 1, não conseguimos visualizar quais classes tiveram mais erros/acertos. Além disso, a perda (loss) é bastante pequena, o que faz sentido dado essas métricas."
      ],
      "metadata": {
        "id": "EfC3qh8js3B-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fazendo o mesmo pra o Bert."
      ],
      "metadata": {
        "id": "MueZUCf14Av2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_model(tokenizer, model, tokenized_train, tokenized_test, y_train, y_test):\n",
        "\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "    train_dataset = TensorDataset(\n",
        "        tokenized_train[\"input_ids\"].clone().detach(),\n",
        "        tokenized_train[\"attention_mask\"].clone().detach(),\n",
        "        torch.tensor(y_train)\n",
        "    )\n",
        "    test_dataset = TensorDataset(\n",
        "        tokenized_test[\"input_ids\"].clone().detach(),\n",
        "        tokenized_test[\"attention_mask\"].clone().detach(),\n",
        "        torch.tensor(y_test)\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device='cpu'\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1):  # Loop over epochs\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Debugging: Print shapes and values\n",
        "            #print(\"Batch input_ids shape train :\", input_ids.shape)\n",
        "            #print(\"Batch attention_mask shape train :\", attention_mask.shape)\n",
        "            #print(\"Batch labels shape train:\", labels.shape)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    acc = []\n",
        "    prec =[]\n",
        "    num_classes = len(set(y_test))\n",
        "    overall_cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    guessed_classes = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Debugging: Print shapes and values\n",
        "            #print(\"Batch input_ids shape:\", input_ids.shape)\n",
        "            #print(\"Batch attention_mask shape:\", attention_mask.shape)\n",
        "            #print(\"Batch labels shape:\", labels.shape)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "            for i in range(len(labels)):\n",
        "                 if predictions[i] != labels[i]:\n",
        "                    guessed_classes.append((predictions[i].item(), labels[i].item()))\n",
        "\n",
        "            eval_loss += outputs.loss.item()\n",
        "\n",
        "\n",
        "\n",
        "            accuracy = accuracy_score(labels, predictions)\n",
        "            acc.append(accuracy)\n",
        "\n",
        "            precision = precision_score(labels, predictions, average=\"weighted\")\n",
        "            prec.append(precision)\n",
        "\n",
        "            print(f\"Accuracy: {accuracy:.3f}\")\n",
        "            print(f\"Precision: {precision:.3f}\")\n",
        "\n",
        "\n",
        "        average_accuracy = np.mean(acc)\n",
        "        average_precision = np.mean(prec)\n",
        "\n",
        "        print(f\"Average Accuracy: {average_accuracy:.3f}\")\n",
        "        print(f\"Average Precision: {average_precision:.3f}\")\n",
        "        print(f\"Evaluation Loss: {eval_loss / len(test_dataloader)}\")\n",
        "\n",
        "\n",
        "        for guessed, correct in guessed_classes:\n",
        "            print(f\"Guessed: {guessed} (Correct: {correct})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AAgvUwov4EEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Carregamento dos modelos BERT e Bertimbal\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(\"neuralmind/bert-base-portuguese-cased\", num_labels=len(set(y_train)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae17c07-c58f-4dff-8653-ab5c1d434329",
        "id": "GE8QKIy-4AwA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_bert_train = bert_tokenizer(dataset_train[\"text\"], padding=\"max_length\", truncation=True, max_length=300, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "jJHvHEWYSgha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_bert_test = bert_tokenizer(dataset_test[\"text\"], padding=\"max_length\", truncation=True, max_length=300, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "30xIP6TlSnuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo é avaliado em batches, por isso imprimo as acurácias e precisões de cada um. Como ambos são 1, não conseguimos visualizar quais classes tiveram mais erros/acertos. Além disso, a perda (loss) é bastante pequena, o que faz sentido dado essas métricas."
      ],
      "metadata": {
        "id": "Yk6JLm4E4AwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(bert_tokenizer, bert_model, tokenized_bert_train, tokenized_bert_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psn5OysoSQ9p",
        "outputId": "7974f887-ff7c-4442-8eb0-fc2e47185f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.400\n",
            "Precision: 0.400\n",
            "Accuracy: 0.667\n",
            "Precision: 0.500\n",
            "Average Accuracy: 0.533\n",
            "Average Precision: 0.450\n",
            "Evaluation Loss: 1.2417539358139038\n",
            "Guessed: 1 (Correct: 4)\n",
            "Guessed: 1 (Correct: 0)\n",
            "Guessed: 1 (Correct: 2)\n",
            "Guessed: 1 (Correct: 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "Tm7yMnbEPpGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2ec44b-98dd-4953-ddc4-2d04cf8666d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4, 1, 3, 1, 3, 1, 1, 0, 2, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como o BERT apresentou erros, criei uma função modificada para ele, que nos permite saber qual classe ele previu e qual era a correta. Podemos observar que ele geralmente prevê a classe 1, que é a classe com o maior número de amostras."
      ],
      "metadata": {
        "id": "OyQ48cLC4IV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Conclusao\n",
        "\n",
        "O BERTimbau teve a melhor performance, o que era esperado, considerando que ele já foi pré-treinado em português, ao contrário do BERT. Além disso, o BERT tende a prever a classe com maior disponibilidade no dataset."
      ],
      "metadata": {
        "id": "y7MuvS9L5V_M"
      }
    }
  ]
}