{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zcgf6mN7Km8"
      },
      "outputs": [],
      "source": [
        "#!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "0zUjRiIAlvjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "rQhj5TfU7PfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ybvz_njv7RGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "NqIQaKefIBpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import AdamW\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "S3DUBiQc79mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhbJSjF_7Sj0",
        "outputId": "9e5920c4-f101-44a7-85ea-51403f559a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBL5jVMD7T-P",
        "outputId": "cf65627e-3f61-4c58-a411-da40254412fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1CNLowRdVtLOrHbCZbdjg3IVys53iPk7m/datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "Ocv7MmL0mSvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "input_file = 'articles.csv'\n",
        "output_file = 'corrected_articles.csv'\n",
        "\n",
        "# Lista para armazenar as linhas válidas\n",
        "data = []\n",
        "\n",
        "# Ler o arquivo CSV manualmente\n",
        "with open(input_file, 'r', encoding='utf-8') as infile:\n",
        "    reader = csv.reader(infile)\n",
        "    header = next(reader)  # Ler o cabeçalho\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "# Criar o DataFrame a partir dos dados\n",
        "art_df = pd.DataFrame(data, columns=header)\n"
      ],
      "metadata": {
        "id": "AcmNBsoj7Vq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "art_df.columns\n",
        "art_df = art_df.drop(columns = ['title','date','subcategory', 'link'])"
      ],
      "metadata": {
        "id": "6Mms4gw_7kcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the documentation on the Hugging Face website, it's necessary to tokenize the texts that will be used in training for fine-tuning these models. Therefore, also for memory considerations, I chose to keep only the columns containing the news body and its corresponding category\n"
      ],
      "metadata": {
        "id": "bO93aiu5npnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Codificar as categorias\n",
        "label_encoder = LabelEncoder()\n",
        "art_df['category'] = label_encoder.fit_transform(art_df['category'])\n",
        "art_df = art_df.rename(columns={'category': 'label'})\n"
      ],
      "metadata": {
        "id": "xAq4qqGX7mjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classes are in text format, which is not ideal for model training. Therefore, the label_encoder function converts the nominal classes into numeric formats."
      ],
      "metadata": {
        "id": "6dXubQXvoha-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicação da operação usando pandas e tqdm para acompanhar o progresso\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()  # Ativar tqdm com pandas\n",
        "\n",
        "# Função para truncar o texto após o último ponto\n",
        "def truncate_text(s):\n",
        "    if isinstance(s, str):\n",
        "        return s[:s.rfind('.') + 1]\n",
        "    return ''\n",
        "\n",
        "# Aplicar a função para truncar o texto\n",
        "art_df['text'] = art_df['text'].progress_apply(truncate_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm41NHf97ogw",
        "outputId": "af962dc2-1312-458c-e22a-1d6e2d1fba1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 167053/167053 [00:00<00:00, 425392.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the tokenization process, I was facing issues. Tokenization was returning errors and not functioning properly, until I searched through tutorials and realized that the problem was the text not being terminated with '.'. In other words, even though the body of the news article had ended, there were noise elements such as advertisements after the message body, requiring cleaning to maintain consistency. The Transformer interprets ',' as a stopping point, so the lack of proper message termination was causing errors. truncate_text resolves this issue."
      ],
      "metadata": {
        "id": "KNMOfcLUpIim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divida o DataFrame em treinamento (80%) e uma parte temporária (20%)\n",
        "df_train, df_temp = train_test_split(art_df, test_size=0.9999, random_state=10)\n",
        "\n",
        "# Divida a parte temporária em validação (50%) e teste (50%)\n",
        "df_val, df_test = train_test_split(df_train, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "JWLNIFaL7qcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data splitting stage is quite delicate. The dataset is very large and was causing memory issues, so I had to use a configuration that allowed me to run the experiments. Since I believe the goal of the activity is to test our skills with the models, learn how to preprocess them, among other aspects, I don't see a problem with the size of the data I can use in the experiments."
      ],
      "metadata": {
        "id": "w3dzPUeWqImY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9E1UqeJ7sLU",
        "outputId": "28b9de07-2cbe-44c4-bed9-a01fe6014145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16, 2), (8, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "def remove_missing_classes(df_train, df_test):\n",
        "  \"\"\"\n",
        "  Removes rows in df_train where the label is present in df_train but not in df_test.\n",
        "\n",
        "  Args:\n",
        "      df_train (pandas.DataFrame): The training DataFrame.\n",
        "      df_test (pandas.DataFrame): The testing DataFrame.\n",
        "\n",
        "  Returns:\n",
        "      pandas.DataFrame: The filtered df_train with missing classes removed.\n",
        "  \"\"\"\n",
        "\n",
        "  classes_train = set(df_train['label'].unique())\n",
        "  classes_test = set(df_test['label'].unique())\n",
        "\n",
        "  missing_classes = classes_train.difference(classes_test)\n",
        "\n",
        "  return df_train[~df_train['label'].isin(missing_classes)]\n",
        "\n",
        "# Example usage:\n",
        "df_train = remove_missing_classes(df_train, df_test)\n",
        "print(set(df_train['label']))\n",
        "print(set(df_test['label'].unique()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMVkvM367uda",
        "outputId": "fe6a4145-0fea-4541-8dfd-9ba2fb6eda18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{35, 9, 12, 46, 26}\n",
            "{35, 9, 12, 46, 26}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the dataset's size, some classes are present in the training set but absent in the test set, causing issues. Therefore, the removing_missing_classes function aims to ensure that both sets have the same classes."
      ],
      "metadata": {
        "id": "KxcgrauoquBg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Function\n",
        "The train_evaluate_model function was created to be used with both requested models, enabling a fair comparison of results. For this purpose, it receives the models, tokenizers, as well as the pre-tokenized training and test datasets"
      ],
      "metadata": {
        "id": "M7pTDc7NrKcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_model(tokenizer, model, tokenized_train, tokenized_test, y_train, y_test):\n",
        "\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "    train_dataset = TensorDataset(\n",
        "        tokenized_train[\"input_ids\"].clone().detach(),\n",
        "        tokenized_train[\"attention_mask\"].clone().detach(),\n",
        "        torch.tensor(y_train)\n",
        "    )\n",
        "    test_dataset = TensorDataset(\n",
        "        tokenized_test[\"input_ids\"].clone().detach(),\n",
        "        tokenized_test[\"attention_mask\"].clone().detach(),\n",
        "        torch.tensor(y_test)\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device='cpu'\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1):  # Loop over epochs\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Debugging: Print shapes and values\n",
        "            #print(\"Batch input_ids shape train :\", input_ids.shape)\n",
        "            #print(\"Batch attention_mask shape train :\", attention_mask.shape)\n",
        "            #print(\"Batch labels shape train:\", labels.shape)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    acc = []\n",
        "    prec =[]\n",
        "    num_classes = len(set(y_test))\n",
        "    overall_cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Debugging: Print shapes and values\n",
        "            #print(\"Batch input_ids shape:\", input_ids.shape)\n",
        "            #print(\"Batch attention_mask shape:\", attention_mask.shape)\n",
        "            #print(\"Batch labels shape:\", labels.shape)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "            eval_loss += outputs.loss.item()\n",
        "\n",
        "\n",
        "\n",
        "            accuracy = accuracy_score(labels, predictions)\n",
        "            acc.append(accuracy)\n",
        "\n",
        "            precision = precision_score(labels, predictions, average=\"weighted\")\n",
        "            prec.append(precision)\n",
        "\n",
        "            print(f\"Accuracy: {accuracy:.3f}\")\n",
        "            print(f\"Precision: {precision:.3f}\")\n",
        "\n",
        "\n",
        "        average_accuracy = np.mean(acc)\n",
        "        average_precision = np.mean(prec)\n",
        "\n",
        "        print(f\"Average Accuracy: {average_accuracy:.3f}\")\n",
        "        print(f\"Average Precision: {average_precision:.3f}\")\n",
        "        print(f\"Evaluation Loss: {eval_loss / len(test_dataloader)}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TGTszbtD7zhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Bertimbal\n",
        "\n"
      ],
      "metadata": {
        "id": "R-faqAEVrueI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Carregamento dos modelos BERT e Bertimbal\n",
        "\n",
        "bertimbal_tokenizer = AutoTokenizer.from_pretrained(\"tiagoblima/newsdata-bertimbal\")\n",
        "bertimbal_model = AutoModelForSequenceClassification.from_pretrained(\"tiagoblima/newsdata-bertimbal\")\n"
      ],
      "metadata": {
        "id": "4XLb2Syi9Rxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Data Preparation\n",
        "The datasets need to be dataset-type objects. Therefore, it's necessary to convert both the training and test sets to this format. Additionally, since the data selection was previously done randomly, the resulting classes in my dataset may not be ordered. Hence, the convert_class_labels function associates each class with a numerical order (0, 1, 2, etc.), preventing issues during training."
      ],
      "metadata": {
        "id": "baNAN7ucrybi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = Dataset.from_pandas(df_train)\n",
        "dataset_test = Dataset.from_pandas(df_test)"
      ],
      "metadata": {
        "id": "aCXq7NV59YI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = dataset_train['label']\n",
        "y_test = dataset_test['label']"
      ],
      "metadata": {
        "id": "kf84KqML9rR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_class_labels(labels):\n",
        "  \"\"\"\n",
        "  Converts a list of class labels (integers) to numerical representations (starting from 0).\n",
        "\n",
        "  Args:\n",
        "      labels (list): A list of integer class labels.\n",
        "\n",
        "  Returns:\n",
        "      torch.Tensor: A tensor containing the numerical representations of the class labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a dictionary to map unique class labels to numerical representations\n",
        "  class_to_index = {label: i for i, label in enumerate(sorted(set(labels)))}\n",
        "\n",
        "  # Convert each label in the original list to its numerical representation\n",
        "  numerical_labels = [class_to_index[label] for label in labels]\n",
        "\n",
        "  # Convert the list to a PyTorch tensor\n",
        "  return numerical_labels"
      ],
      "metadata": {
        "id": "AwfBONJiCIhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = convert_class_labels(y_train)\n",
        "y_test =  convert_class_labels(y_test)"
      ],
      "metadata": {
        "id": "jhuY-n2xCLxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(y_train), set(y_test), len(dataset_test[\"text\"]), len(y_test), len(dataset_train[\"text\"]), len(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KoPDtseLHoj",
        "outputId": "3e60136a-c851-43e5-aed3-40437cabd589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, 8, 8, 12, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization, training and evaluation"
      ],
      "metadata": {
        "id": "eBYvnSKYspLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_bertimbau_train = bertimbal_tokenizer(dataset_train[\"text\"], padding=\"max_length\", truncation=True, max_length=300, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "olVThxw59tjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_bertimbau_test = bertimbal_tokenizer(dataset_test[\"text\"], padding=\"max_length\", truncation=True, max_length=300, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "oYStrlpsAlCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(bertimbal_tokenizer, bertimbal_model, tokenized_bertimbau_train, tokenized_bertimbau_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57iQyrr3AoBx",
        "outputId": "dceeaf88-77a4-4fa8-c562-0563595b8b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.000\n",
            "Precision: 1.000\n",
            "Accuracy: 1.000\n",
            "Precision: 1.000\n",
            "Average Accuracy: 1.000\n",
            "Average Precision: 1.000\n",
            "Evaluation Loss: 0.0019725957536138594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is evaluated in batches, so I print the accuracies and precisions for each batch. Since both are 1, we can't visualize which classes had more errors/accuracies. Additionally, the loss is quite small, which makes sense given these metrics."
      ],
      "metadata": {
        "id": "EfC3qh8js3B-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fazendo o mesmo pra o Bert."
      ],
      "metadata": {
        "id": "MueZUCf14Av2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_model(tokenizer, model, tokenized_train, tokenized_test, y_train, y_test):\n",
        "\n",
        "    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "    train_dataset = TensorDataset(\n",
        "        tokenized_train[\"input_ids\"].clone().detach(),\n",
        "        tokenized_train[\"attention_mask\"].clone().detach(),\n",
        "        torch.tensor(y_train)\n",
        "    )\n",
        "    test_dataset = TensorDataset(\n",
        "        tokenized_test[\"input_ids\"].clone().detach(),\n",
        "        tokenized_test[\"attention_mask\"].clone().detach(),\n",
        "        torch.tensor(y_test)\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=5, shuffle=True)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device='cpu'\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(1):  # Loop over epochs\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Debugging: Print shapes and values\n",
        "            #print(\"Batch input_ids shape train :\", input_ids.shape)\n",
        "            #print(\"Batch attention_mask shape train :\", attention_mask.shape)\n",
        "            #print(\"Batch labels shape train:\", labels.shape)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    acc = []\n",
        "    prec =[]\n",
        "    num_classes = len(set(y_test))\n",
        "    overall_cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    guessed_classes = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            # Debugging: Print shapes and values\n",
        "            #print(\"Batch input_ids shape:\", input_ids.shape)\n",
        "            #print(\"Batch attention_mask shape:\", attention_mask.shape)\n",
        "            #print(\"Batch labels shape:\", labels.shape)\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            predictions = torch.argmax(outputs.logits, dim=1)\n",
        "            for i in range(len(labels)):\n",
        "                 if predictions[i] != labels[i]:\n",
        "                    guessed_classes.append((predictions[i].item(), labels[i].item()))\n",
        "\n",
        "            eval_loss += outputs.loss.item()\n",
        "\n",
        "\n",
        "\n",
        "            accuracy = accuracy_score(labels, predictions)\n",
        "            acc.append(accuracy)\n",
        "\n",
        "            precision = precision_score(labels, predictions, average=\"weighted\")\n",
        "            prec.append(precision)\n",
        "\n",
        "            print(f\"Accuracy: {accuracy:.3f}\")\n",
        "            print(f\"Precision: {precision:.3f}\")\n",
        "\n",
        "\n",
        "        average_accuracy = np.mean(acc)\n",
        "        average_precision = np.mean(prec)\n",
        "\n",
        "        print(f\"Average Accuracy: {average_accuracy:.3f}\")\n",
        "        print(f\"Average Precision: {average_precision:.3f}\")\n",
        "        print(f\"Evaluation Loss: {eval_loss / len(test_dataloader)}\")\n",
        "\n",
        "\n",
        "        for guessed, correct in guessed_classes:\n",
        "            print(f\"Guessed: {guessed} (Correct: {correct})\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AAgvUwov4EEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Carregamento dos modelos BERT e Bertimbal\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(\"neuralmind/bert-base-portuguese-cased\", num_labels=len(set(y_train)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae17c07-c58f-4dff-8653-ab5c1d434329",
        "id": "GE8QKIy-4AwA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_bert_train = bert_tokenizer(dataset_train[\"text\"], padding=\"max_length\", truncation=True, max_length=300, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "jJHvHEWYSgha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_bert_test = bert_tokenizer(dataset_test[\"text\"], padding=\"max_length\", truncation=True, max_length=300, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "30xIP6TlSnuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is evaluated in batches, so I print the accuracies and precisions for each batch. Since both are 1, we can't visualize which classes had more errors/accuracies. Additionally, the loss is quite small, which makes sense given these metrics."
      ],
      "metadata": {
        "id": "Yk6JLm4E4AwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_evaluate_model(bert_tokenizer, bert_model, tokenized_bert_train, tokenized_bert_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psn5OysoSQ9p",
        "outputId": "7974f887-ff7c-4442-8eb0-fc2e47185f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.400\n",
            "Precision: 0.400\n",
            "Accuracy: 0.667\n",
            "Precision: 0.500\n",
            "Average Accuracy: 0.533\n",
            "Average Precision: 0.450\n",
            "Evaluation Loss: 1.2417539358139038\n",
            "Guessed: 1 (Correct: 4)\n",
            "Guessed: 1 (Correct: 0)\n",
            "Guessed: 1 (Correct: 2)\n",
            "Guessed: 1 (Correct: 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "Tm7yMnbEPpGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2ec44b-98dd-4953-ddc4-2d04cf8666d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4, 1, 3, 1, 3, 1, 1, 0, 2, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As BERT presented errors, I created a modified function for it that allows us to know which class it predicted and which one was correct. We can observe that it generally predicts class 1, which is the class with the highest number of samples."
      ],
      "metadata": {
        "id": "OyQ48cLC4IV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Conclusion\n",
        "\n",
        "BERTimbau had the best performance, which was expected, considering it was pre-trained in Portuguese, unlike BERT. Additionally, BERT tends to predict the class with the highest availability in the dataset."
      ],
      "metadata": {
        "id": "y7MuvS9L5V_M"
      }
    }
  ]
}